{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c507f0b-382d-43e7-a745-a1b67e38d0a5",
   "metadata": {},
   "source": [
    "#AssQ 26-March , Regression -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd54653-78a2-4caa-a823-122aec545ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1. Explain the difference between simple linear regression and multiple linear regression. Provide an \n",
    "# example of each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a78eac-3457-46e8-891e-7583e21eda26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple linear regression has only one x and one y variable.\n",
    "# Example- the relationship between rainfall and soil erosion\n",
    "# Multiple linear regression has one y and two or more x variables.\n",
    "# For instance, when we predict rent based on square feet alone that is simple linear regression.\n",
    "\n",
    "# Simple linear regression is a linear approach to model the relationship between a dependent variable \n",
    "# and one independent variable. Multiple linear regression uses a linear function to predict the value of\n",
    "# a dependent variable containing the function n independent variables.\n",
    "\n",
    "# Multiple Linear Regression is one of the important regression algorithms which models the linear \n",
    "# relationship between a single dependent continuous variable and more than one independent variable.\n",
    "# Example: Prediction of CO2 emission based on engine size and number of cylinders in a car."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00a8fe9-13f0-4915-a259-effbc686dcfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e25beb04-346a-4599-aa17-f7e60efc38bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2. Discuss the assumptions of linear regression. How can you check whether these assumptions hold in \n",
    "# a given dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bb6c10-e2c1-4d7b-a53d-c3420d56734f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Assumptions of Linear Regression-\n",
    "# Assumption One: Linearity of the Data.\n",
    "# Assumption Two: Predictors (x) are Independent & Observed with Negligible Error.\n",
    "# Assumption Three: Residual Errors have a Mean Value of Zero.\n",
    "# Assumption Four: Residual Errors have Constant Variance.\n",
    "\n",
    "# The chosen sample is representative of the population.\n",
    "# There is a linear relationship between the independent variable(s) and the dependent variable.\n",
    "# All the variables are normally distributed; to check, plot a histogram of the residuals.\n",
    "\n",
    "# There should be a linear and additive relationship between dependent (response) variable and\n",
    "# independent (predictor) variable(s). ...\n",
    "# There should be no correlation between the residual (error) terms. ...\n",
    "# The independent variables should not be correlated. ...\n",
    "# The error terms must have constant variance.\n",
    "\n",
    "# check whether these assumptions hold in a given dataset-\n",
    "# The simple rule is: If all else is equal and A has higher severity than B, then test A before B.\n",
    "# The second factor is the probability of an assumption being true. What is counterintuitive to many\n",
    "# is that assumptions that have a lower probability  of being true should be tested first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a3cd55-9a89-4638-a662-9ad65e73aaef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c22fc92e-f024-4329-800e-8ea9e664027e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3. How do you interpret the slope and intercept in a linear regression model? Provide an example using \n",
    "# a real-world scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1313f03e-cf60-4743-9cd2-3eb7b1e96f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpret the intercept. If the duration of the dive is 0 seconds, then we predict the depth of the dive is 0.015 yards.\n",
    "# The easiest way to understand and interpret slope and intercept in linear models\n",
    "#  is to first understand the slope-intercept formula: y = mx + b.\n",
    "# M is the slope or the consistent change between x and y, and b is the y-intercept. Often,\n",
    "# the y-intercept represents the starting point of the equation.\n",
    "\n",
    "# Interpret the slope: If the speed of the club hitting the ball increases by 1 mph, \n",
    "# then the model predicts that the length the ball travels increases by 57.66 yards.\n",
    "# Interpret the intercept: If the ball is hit with a speed of 0 mph, then the model predicts that\n",
    "# the length the ball travels will be 3.18 yards.\n",
    "\n",
    "# We will look at real-life applications of slope, including roofs, roads, handicap ramps,\n",
    "# funiculars, cable cars, mountains for skiing, downhill cycling, and snowboarding/dirtboarding, \n",
    "# roller coasters, skate ramps, and BMX jumps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64196fdd-84ac-4bb6-a09b-a174a400fe3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69e391d1-8953-48cc-88e0-68d7fc0d7b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4. Explain the concept of gradient descent. How is it used in machine learning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8f3de4-6177-48f7-a42d-748a1cb87c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient descent is an optimization algorithm which is commonly-used to train machine learning models .\n",
    "# Training data helps these models learn over time, and the cost function within gradient descent \n",
    "# specifically acts as a barometer, gauging its accuracy with each iteration of parameter updates.\n",
    "\n",
    "# Gradient Descent is known as one of the most commonly used optimization algorithms to train\n",
    "# machine learning models by means of minimizing errors between actual and expected results. \n",
    "\n",
    "# Gradient descent (GD) is an iterative first-order optimisation algorithm used to find a local \n",
    "# minimum/maximum of a given function. This method is commonly used in machine learning (ML) \n",
    "# to minimise a cost/loss function (e.g. in a linear regression).\n",
    "\n",
    "# Gradient Descent is an algorithm that is used to optimize the cost function or the error of the model.\n",
    "# It is used to find the minimum value of error possible in your model. Gradient Descent can be thought \n",
    "# of as the direction you have to take to reach the least possible error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5c96d5-a870-46d3-a0f3-10797b1b8eeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5935d02-eb6c-40c9-aeb4-2e510f08d403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5. Describe the multiple linear regression model. How does it differ from simple linear regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75cd1e8-721e-4a23-9f96-837251e90eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple regression is a broader class of regressions that encompasses linear and nonlinear regressions\n",
    "# with multiple explanatory variables. Whereas linear regress only has one independent variable impacting \n",
    "# the slope of the relationship, multiple regression incorporates multiple independent variables.\n",
    "\n",
    "# Simple linear regression is a linear approach to model the relationship between a dependent variable \n",
    "# and one independent variable. Multiple linear regression uses a linear function to predict the value of\n",
    "# a dependent variable containing the function n independent variables.\n",
    "\n",
    "# A simple linear regression can accurately capture the relationship between two variables in simple relationships. \n",
    "# On the other hand, multiple linear regression can capture more complex interactions that require more thought.\n",
    "# A multiple regression model uses more than one independent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036d4de5-7318-4163-8437-8c05c6a75f3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8540e6f6-95b0-4f30-aeae-c8c90b4ea9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q6. Explain the concept of multicollinearity in multiple linear regression. How can you detect and \n",
    "# address this issue?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfd3135-8c77-4e7f-a4c2-c4bba08cec81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multicollinearity happens when independent variables in the regression model are highly correlated to each other.\n",
    "# It makes it hard to interpret of model and also creates an overfitting problem.\n",
    "# It is a common assumption that people test before selecting the variables into the regression model.\n",
    "\n",
    "# Multicollinearity occurs when two or more independent variables in a data frame have\n",
    "# a high correlation with one another in a regression model.\n",
    "# This means that one independent variable can be predicted from another in a regression model\n",
    "\n",
    "# Addressing multicollinearity\n",
    "# Removing variables. A straightforward method of correcting multicollinearity is removing one or\n",
    "# more variables showing a high correlation.\n",
    "# Using techniques such as partial least squares regression (PLS) and principal component analysis (PCA). \n",
    "# Centering the variables.\n",
    "\n",
    "# A statistical technique called the variance inflation factor (VIF) can be used to detect and measure \n",
    "# the amount of collinearity in a multiple regression model. VIF measures how much the variance of the\n",
    "# estimated regression coefficients are inflated as compared to when the predictor variables are not linearly related."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b5608b-84e3-4208-83a6-8b8e474be0dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82c9ead4-3def-4e43-8373-0b019a0b00fc",
   "metadata": {},
   "source": [
    "Q7. Describe the polynomial regression model. How is it different from linear regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8456060-fca6-42d6-af63-5d58e87bf9b9",
   "metadata": {},
   "source": [
    "Polynomial regression is a form of Linear regression where only due to the Non-linear relationship between\n",
    "dependent and independent variables, we add some polynomial terms to linear regression to convert \n",
    "it into Polynomial regression.\n",
    "\n",
    "Polynomial regression, abbreviated E(y |x), describes the fitting of a nonlinear relationship \n",
    "between the value of x and the conditional mean of y.It usually corresponded to the least-squares method.\n",
    "\n",
    "Polynomial provides the best approximation of the relationship between the dependent and independent variable.\n",
    "A Broad range of function can be fit under it. Polynomial basically fits a wide range of curvature.\n",
    "\n",
    "Polynomial regression is one of the machine learning algorithms used for making predictions. For example,\n",
    "it is widely applied to predict the spread rate of COVID-19 andother infectious diseases.\n",
    "\n",
    "Polynomial regression is non-linear in the way that x is not linearly correlated with f(x,β); \n",
    "the equation itself is still linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03fce90-3a81-495b-bca5-0c20798dd692",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0bbaf10-cc02-4300-8d51-209e9781e406",
   "metadata": {},
   "source": [
    "Q8. What are the advantages and disadvantages of polynomial regression compared to linear \n",
    "regression? In what situations would you prefer to use polynomial regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b08535-0a74-408a-9d0a-af63ee5e75ff",
   "metadata": {},
   "source": [
    "Polynomial provides the best approximation of the relationship between the dependent and independent variable. \n",
    "A Broad range of function can be fit under it. Polynomial basically fits a wide range of curvature.\n",
    "\n",
    "The polynomial regression is flexible enough to get fitted in a vast range of curvatures. \n",
    "A broad range of functions can easily fit under it.\n",
    "The polynomial regression offers the best approximation of the relationship\n",
    "between the two dependent and independent variables.\n",
    "\n",
    "The main advantages of polynomial fits include reasonable flexibility for data that is not too complicated,\n",
    "and they are linear, which means the fitting process is simple. \n",
    "The main disadvantage is that high-degree fits can become unstable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
